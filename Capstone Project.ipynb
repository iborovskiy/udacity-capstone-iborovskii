{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "This capstone project contains a data pipeline implementation that transforms source data into the target data model for the US immigration data analysis.\n",
    "\n",
    "The project uses AWS S3 data lake for storing low and high priority data and Spark cluster thar runs ETL pipeline logic transforming original data into analytics tables for the subsequent use by the analytics teams.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "THis project implements the following tasks:\n",
    "1. Gather raw data from multiple sources\n",
    "2. Cleaning and validating source data\n",
    "3. Storing source data into data lake, both high-value and low-value\n",
    "4. Transforming source data into the target data model containing set of fact and dimension tables for the future use of analytics team.\n",
    "\n",
    "Target data model will let us analyze data on several aggregation levels: by time, by location (city, airport), by climate conditions etc.\n",
    "\n",
    "As main storage option for our data late we chose AWS S3.\n",
    "All computational tasks of ETL were implemented using Apache Spark.\n",
    "\n",
    "#### Describe and Gather Data \n",
    "As input data we use four datasets:\n",
    "\n",
    "**Main dataset**: I94 Immigration Data from the US National Tourism and Trade. It contains statistcs on immigration to the USA (point of entry and detailed info on immigrants).\n",
    "\n",
    "Source: https://travel.trade.gov/research/reports/i94/historical/2016.html\n",
    "\n",
    "**Supplementary datasets**:\n",
    "\n",
    "_U.S. City Demographic Data_: This data comes from OpenSoft and contains various population statistics on every US city.\n",
    "\n",
    "Source: https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/\n",
    "\n",
    "_Airport Code Table_: This dataset contains airport codes, geo references and corresponding cities.\n",
    "\n",
    "Source: https://datahub.io/core/airport-codes#data\n",
    "\n",
    "_World Temperature Data_: This dataset comes from Kaggle and contains various temperature statistics for a large number of world cities.\n",
    "\n",
    "Source: https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data\n",
    "\n",
    "**Additional tables**:\n",
    "Following support tables were derived from source data dictionary for I94 Immigration Data (contained in file **I94_SAS_Labels_Descriptions.SAS**):\n",
    "\n",
    "1. _countries.csv_: Dictionary for country from i94cit and i94res columns\n",
    "\n",
    "2. _i94ports.csv_: Dictionary for link between **i94port** field and city of entrance.\n",
    "\n",
    "3. _i94mode.csv_: Dctionary for text representation of border cross method in **i94mode** field \n",
    "\n",
    "4. _i94visa.csv_: Dictionary for text representation of visa type in **i94visa** field \n",
    "\n",
    "5. _us_states.csv_: Dictionary for full names of US States"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Below are short fragments of information from every data source.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**I94 Immigration Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We load sample fragment of immigration data from file **immigration_data_sample.csv** and join it to dictionary tables.\n",
    "Full i94 immigration dataset is stored in parquet format.\n",
    "\n",
    "Let's look at the most interesting fields from immigration data set.\n",
    "\n",
    "Description of all I94 fields can be found in **I94_SAS_Labels_Descriptions.SAS** dictionary file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>country_of_residence</th>\n",
       "      <th>country_of_citizenship</th>\n",
       "      <th>city_of_entry</th>\n",
       "      <th>state_of_entry_code</th>\n",
       "      <th>state_of_entry_full</th>\n",
       "      <th>border_cross_method</th>\n",
       "      <th>type_of_visa</th>\n",
       "      <th>class_of_admission</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>arr_date</th>\n",
       "      <th>dep_date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4084316</td>\n",
       "      <td>JAPAN</td>\n",
       "      <td>JAPAN</td>\n",
       "      <td>HONOLULU</td>\n",
       "      <td>HI</td>\n",
       "      <td>HAWAII</td>\n",
       "      <td>Air</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>WT</td>\n",
       "      <td>F</td>\n",
       "      <td>61</td>\n",
       "      <td>2016-04-22</td>\n",
       "      <td>2016-04-29</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4422636</td>\n",
       "      <td>MEXICO AIR SEA AND NOT REPORTED (I-94 NO LAND...</td>\n",
       "      <td>MEXICO AIR SEA AND NOT REPORTED (I-94 NO LAND...</td>\n",
       "      <td>MCALLEN</td>\n",
       "      <td>TX</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>Air</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>B2</td>\n",
       "      <td>M</td>\n",
       "      <td>26</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5291768</td>\n",
       "      <td>QATAR</td>\n",
       "      <td>QATAR</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>CA</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>Air</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>B2</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>2016-04-28</td>\n",
       "      <td>2016-05-07</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>985523</td>\n",
       "      <td>FRANCE</td>\n",
       "      <td>FRANCE</td>\n",
       "      <td>CHAMPLAIN</td>\n",
       "      <td>NY</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>Land</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>WT</td>\n",
       "      <td>F</td>\n",
       "      <td>19</td>\n",
       "      <td>2016-04-06</td>\n",
       "      <td>2016-04-09</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1481650</td>\n",
       "      <td>GUATEMALA</td>\n",
       "      <td>GUATEMALA</td>\n",
       "      <td>ATLANTA</td>\n",
       "      <td>GA</td>\n",
       "      <td>GEORGIA</td>\n",
       "      <td>Air</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>B2</td>\n",
       "      <td>M</td>\n",
       "      <td>51</td>\n",
       "      <td>2016-04-08</td>\n",
       "      <td>2016-06-01</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                               country_of_residence  \\\n",
       "0  4084316                                              JAPAN   \n",
       "1  4422636   MEXICO AIR SEA AND NOT REPORTED (I-94 NO LAND...   \n",
       "2  5291768                                              QATAR   \n",
       "3   985523                                             FRANCE   \n",
       "4  1481650                                          GUATEMALA   \n",
       "\n",
       "                              country_of_citizenship city_of_entry  \\\n",
       "0                                              JAPAN      HONOLULU   \n",
       "1   MEXICO AIR SEA AND NOT REPORTED (I-94 NO LAND...       MCALLEN   \n",
       "2                                              QATAR   LOS ANGELES   \n",
       "3                                             FRANCE     CHAMPLAIN   \n",
       "4                                          GUATEMALA       ATLANTA   \n",
       "\n",
       "  state_of_entry_code state_of_entry_full border_cross_method type_of_visa  \\\n",
       "0                  HI              HAWAII                 Air     Pleasure   \n",
       "1                  TX               TEXAS                 Air     Pleasure   \n",
       "2                  CA          CALIFORNIA                 Air     Pleasure   \n",
       "3                  NY            NEW YORK                Land     Pleasure   \n",
       "4                  GA             GEORGIA                 Air     Pleasure   \n",
       "\n",
       "  class_of_admission gender  age    arr_date    dep_date  year  month  day  \n",
       "0                 WT      F   61  2016-04-22  2016-04-29  2016      4   22  \n",
       "1                 B2      M   26  2016-04-23  2016-04-24  2016      4   23  \n",
       "2                 B2      M   25  2016-04-28  2016-05-07  2016      4   28  \n",
       "3                 WT      F   19  2016-04-06  2016-04-09  2016      4    6  \n",
       "4                 B2      M   51  2016-04-08  2016-06-01  2016      4    8  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read in sample data file 'immigration_data_sample.csv'\n",
    "i94_df = spark.read.option(\"header\", True).csv('immigration_data_sample.csv')\n",
    "# Read in country dictionary from 'countries.csv'\n",
    "country_df = spark.read.option(\"header\", True).option(\"delimiter\", \";\").csv('countries.csv')\n",
    "# Read in port dictionary from 'i94ports.csv'\n",
    "port_df = spark.read.option(\"header\", True).option(\"delimiter\", \";\").csv('i94ports.csv')\n",
    "# Read in port dictionary from 'i94mode.csv'\n",
    "mode_df = spark.read.option(\"header\", True).option(\"delimiter\", \";\").csv('i94mode.csv')\n",
    "# Read in port dictionary from 'i94visa.csv'\n",
    "visa_df = spark.read.option(\"header\", True).option(\"delimiter\", \";\").csv('i94visa.csv')\n",
    "# Read in port dictionary from 'us_states.csv'\n",
    "states_df = spark.read.option(\"header\", True).option(\"delimiter\", \";\").csv('us_states.csv')\n",
    "# create a temporary views against which you can run SQL queries\n",
    "i94_df.createOrReplaceTempView(\"i94_table\")\n",
    "country_df.createOrReplaceTempView(\"country_table\")\n",
    "port_df.createOrReplaceTempView(\"port_table\")\n",
    "mode_df.createOrReplaceTempView(\"mode_table\")\n",
    "visa_df.createOrReplaceTempView(\"visa_table\")\n",
    "states_df.createOrReplaceTempView(\"states_df\")\n",
    "\n",
    "i94_source_table = spark.sql('''\n",
    "        SELECT CAST(cicid AS LONG) id, UPPER(c1.country_name) country_of_residence, UPPER(c2.country_name) country_of_citizenship,\n",
    "                UPPER(p.port_location) city_of_entry, UPPER(p.state) state_of_entry_code, UPPER(s.state) state_of_entry_full, \n",
    "                m.border_cross_method border_cross_method, v.visa_type type_of_visa,\n",
    "                i.visatype class_of_admission, i.gender gender, CAST(i.i94bir AS LONG) age,\n",
    "                date_add(to_date('1960-01-01'), CAST(arrdate AS LONG)) arr_date, date_add(to_date('1960-01-01'), CAST(depdate AS LONG)) dep_date,\n",
    "                YEAR(CAST(date_add(to_date('1960-01-01'), CAST(arrdate AS LONG)) AS DATE)) year,\n",
    "                MONTH(CAST(date_add(to_date('1960-01-01'), CAST(arrdate AS LONG)) AS DATE)) month,\n",
    "                DAY(CAST(date_add(to_date('1960-01-01'), CAST(arrdate AS LONG)) AS DATE)) day\n",
    "        FROM i94_table i\n",
    "        JOIN country_table c1\n",
    "        ON CAST(i.i94res AS LONG) = c1.code\n",
    "        JOIN country_table c2\n",
    "        ON CAST(i.i94cit AS LONG) = c2.code\n",
    "        JOIN port_table p\n",
    "        ON i.i94port = p.code\n",
    "        JOIN mode_table m\n",
    "        ON CAST(i94mode AS LONG) = m.code\n",
    "        JOIN visa_table v\n",
    "        ON CAST(i94visa AS LONG) = v.code\n",
    "        JOIN states_df s\n",
    "        ON p.state = s.code\n",
    "''')\n",
    "i94_source_table.createOrReplaceTempView(\"i94_source_table\")\n",
    "# convert to pandas df and display first 5 rows\n",
    "display(spark.sql('''\n",
    "        SELECT *\n",
    "        FROM i94_source_table\n",
    "        LIMIT 5\n",
    "''').toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Let's test access to full dataset in parquet format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94_full_df = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n",
    "i94_full_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_full_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>country_of_residence</th>\n",
       "      <th>country_of_citizenship</th>\n",
       "      <th>city_of_entry</th>\n",
       "      <th>state_of_entry_code</th>\n",
       "      <th>state_of_entry_full</th>\n",
       "      <th>border_cross_method</th>\n",
       "      <th>type_of_visa</th>\n",
       "      <th>class_of_admission</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>arr_date</th>\n",
       "      <th>dep_date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>ALBANIA</td>\n",
       "      <td>ALBANIA</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>Air</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>B2</td>\n",
       "      <td>None</td>\n",
       "      <td>28</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>ALBANIA</td>\n",
       "      <td>ALBANIA</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>Air</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>B2</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>ALBANIA</td>\n",
       "      <td>ALBANIA</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>Air</td>\n",
       "      <td>Business</td>\n",
       "      <td>B1</td>\n",
       "      <td>None</td>\n",
       "      <td>57</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-11</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>ALBANIA</td>\n",
       "      <td>ALBANIA</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>Air</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>B2</td>\n",
       "      <td>None</td>\n",
       "      <td>63</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-14</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>ALBANIA</td>\n",
       "      <td>ALBANIA</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>Air</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>B2</td>\n",
       "      <td>None</td>\n",
       "      <td>57</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-14</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id country_of_residence country_of_citizenship city_of_entry  \\\n",
       "0  16              ALBANIA                ALBANIA      NEW YORK   \n",
       "1  17              ALBANIA                ALBANIA      NEW YORK   \n",
       "2  18              ALBANIA                ALBANIA      NEW YORK   \n",
       "3  19              ALBANIA                ALBANIA      NEW YORK   \n",
       "4  20              ALBANIA                ALBANIA      NEW YORK   \n",
       "\n",
       "  state_of_entry_code state_of_entry_full border_cross_method type_of_visa  \\\n",
       "0                  NY            NEW YORK                 Air     Pleasure   \n",
       "1                  NY            NEW YORK                 Air     Pleasure   \n",
       "2                  NY            NEW YORK                 Air     Business   \n",
       "3                  NY            NEW YORK                 Air     Pleasure   \n",
       "4                  NY            NEW YORK                 Air     Pleasure   \n",
       "\n",
       "  class_of_admission gender  age    arr_date    dep_date  year  month  day  \n",
       "0                 B2   None   28  2016-04-01  2016-04-23  2016      4    1  \n",
       "1                 B2   None    4  2016-04-01  2016-04-23  2016      4    1  \n",
       "2                 B1   None   57  2016-04-01  2016-04-11  2016      4    1  \n",
       "3                 B2   None   63  2016-04-01  2016-04-14  2016      4    1  \n",
       "4                 B2   None   57  2016-04-01  2016-04-14  2016      4    1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read full SAS data and create a preprocessed source table for immigration data\n",
    "i94_full_df.createOrReplaceTempView(\"i94_table\")\n",
    "i94_full_source_table = spark.sql('''\n",
    "        SELECT CAST(cicid AS LONG) id, UPPER(c1.country_name) country_of_residence, UPPER(c2.country_name) country_of_citizenship,\n",
    "                UPPER(p.port_location) city_of_entry, UPPER(p.state) state_of_entry_code, UPPER(s.state) state_of_entry_full, \n",
    "                m.border_cross_method border_cross_method, v.visa_type type_of_visa,\n",
    "                i.visatype class_of_admission, i.gender gender, CAST(i.i94bir AS LONG) age,\n",
    "                date_add(to_date('1960-01-01'), CAST(arrdate AS LONG)) arr_date, date_add(to_date('1960-01-01'), CAST(depdate AS LONG)) dep_date,\n",
    "                YEAR(CAST(date_add(to_date('1960-01-01'), CAST(arrdate AS LONG)) AS DATE)) year,\n",
    "                MONTH(CAST(date_add(to_date('1960-01-01'), CAST(arrdate AS LONG)) AS DATE)) month,\n",
    "                DAY(CAST(date_add(to_date('1960-01-01'), CAST(arrdate AS LONG)) AS DATE)) day\n",
    "        FROM i94_table i\n",
    "        JOIN country_table c1\n",
    "        ON CAST(i.i94res AS LONG) = c1.code\n",
    "        JOIN country_table c2\n",
    "        ON CAST(i.i94cit AS LONG) = c2.code\n",
    "        JOIN port_table p\n",
    "        ON i.i94port = p.code\n",
    "        JOIN mode_table m\n",
    "        ON CAST(i94mode AS LONG) = m.code\n",
    "        JOIN visa_table v\n",
    "        ON CAST(i94visa AS LONG) = v.code\n",
    "        JOIN states_df s\n",
    "        ON p.state = s.code\n",
    "''')\n",
    "i94_full_source_table.createOrReplaceTempView(\"i94_source_table\")\n",
    "\n",
    "# convert to pandas df and display first 5 rows\n",
    "display(spark.sql('''\n",
    "        SELECT *\n",
    "        FROM i94_source_table\n",
    "        LIMIT 5\n",
    "''').toPandas())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2515336"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94_full_source_table.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**U.S. City Demographic Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Let's load first five rows from source csv file and make schema suitable for subsequent processing and joining with other sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>median_age</th>\n",
       "      <th>male_population</th>\n",
       "      <th>female_population</th>\n",
       "      <th>total_population</th>\n",
       "      <th>number_of_veterans</th>\n",
       "      <th>foreign_born</th>\n",
       "      <th>avg_household_size</th>\n",
       "      <th>state_code</th>\n",
       "      <th>race</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SILVER SPRING</td>\n",
       "      <td>MARYLAND</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601</td>\n",
       "      <td>41862</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562</td>\n",
       "      <td>30908</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QUINCY</td>\n",
       "      <td>MASSACHUSETTS</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129</td>\n",
       "      <td>49500</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147</td>\n",
       "      <td>32935</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOOVER</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040</td>\n",
       "      <td>46799</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819</td>\n",
       "      <td>8229</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RANCHO CUCAMONGA</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127</td>\n",
       "      <td>87105</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821</td>\n",
       "      <td>33878</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEWARK</td>\n",
       "      <td>NEW JERSEY</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040</td>\n",
       "      <td>143873</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829</td>\n",
       "      <td>86253</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               city          state  median_age  male_population  \\\n",
       "0     SILVER SPRING       MARYLAND        33.8            40601   \n",
       "1            QUINCY  MASSACHUSETTS        41.0            44129   \n",
       "2            HOOVER        ALABAMA        38.5            38040   \n",
       "3  RANCHO CUCAMONGA     CALIFORNIA        34.5            88127   \n",
       "4            NEWARK     NEW JERSEY        34.6           138040   \n",
       "\n",
       "   female_population  total_population  number_of_veterans  foreign_born  \\\n",
       "0              41862             82463                1562         30908   \n",
       "1              49500             93629                4147         32935   \n",
       "2              46799             84839                4819          8229   \n",
       "3              87105            175232                5821         33878   \n",
       "4             143873            281913                5829         86253   \n",
       "\n",
       "   avg_household_size state_code                       race  count  \n",
       "0                2.60         MD         Hispanic or Latino  25924  \n",
       "1                2.39         MA                      White  58723  \n",
       "2                2.58         AL                      Asian   4759  \n",
       "3                3.18         CA  Black or African-American  24437  \n",
       "4                2.73         NJ                      White  76402  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read in data file 'us-cities-demographics.csv'\n",
    "cities_pop_df = spark.read.option(\"header\", True).option(\"delimiter\", \";\").csv('us-cities-demographics.csv')\n",
    "cities_pop_df = cities_pop_df.toDF('city', 'state', 'median_age', 'male_population', 'female_population', 'total_population', 'number_of_veterans',\n",
    "                                  'foreign_born', 'avg_household_size', 'state_code', 'race', 'count')\n",
    "# create a temporary views against which you can run SQL queries\n",
    "cities_pop_df.createOrReplaceTempView(\"cities_pop_table\")\n",
    "# read data and create a preprocessed source table for demographic data\n",
    "cities_pop_source_table = spark.sql('''\n",
    "        SELECT UPPER(city) city, UPPER(state) state, CAST(median_age AS DOUBLE) median_age, CAST(male_population AS LONG) male_population,\n",
    "                CAST(female_population AS LONG) female_population, CAST(total_population AS LONG) total_population, CAST(number_of_veterans AS LONG) number_of_veterans,\n",
    "                CAST(foreign_born AS LONG) foreign_born, CAST(avg_household_size AS DOUBLE) avg_household_size, state_code, race, CAST(count AS LONG) count\n",
    "        FROM cities_pop_table c\n",
    "''')\n",
    "cities_pop_source_table.createOrReplaceTempView(\"cities_pop_source_table\")\n",
    "# convert to pandas df and display first 5 rows\n",
    "display(spark.sql('''\n",
    "        SELECT *\n",
    "        FROM cities_pop_source_table\n",
    "        LIMIT 5\n",
    "''').toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We can use **city** and **state** to link main immigration data with demographic statistics for points of entry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Airport Code Table**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Let's load first five rows from source csv file and make schema suitable for subsequent processing and joining with other sources.\n",
    "\n",
    "For the purposes of the data model we'll limit records only to USA and working airports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11</td>\n",
       "      <td>PA</td>\n",
       "      <td>BENSALEM</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.933601</td>\n",
       "      <td>40.070801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435</td>\n",
       "      <td>KS</td>\n",
       "      <td>LEOTI</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911</td>\n",
       "      <td>38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450</td>\n",
       "      <td>AK</td>\n",
       "      <td>ANCHOR POINT</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999</td>\n",
       "      <td>59.949200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820</td>\n",
       "      <td>AL</td>\n",
       "      <td>HARVEST</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.770302</td>\n",
       "      <td>34.864799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>small_airport</td>\n",
       "      <td>Fulton Airport</td>\n",
       "      <td>1100</td>\n",
       "      <td>OK</td>\n",
       "      <td>ALEX</td>\n",
       "      <td>00AS</td>\n",
       "      <td>-97.818019</td>\n",
       "      <td>34.942803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            type                  name  elevation_ft iso_region  municipality  \\\n",
       "0       heliport     Total Rf Heliport            11         PA      BENSALEM   \n",
       "1  small_airport  Aero B Ranch Airport          3435         KS         LEOTI   \n",
       "2  small_airport          Lowell Field           450         AK  ANCHOR POINT   \n",
       "3  small_airport          Epps Airpark           820         AL       HARVEST   \n",
       "4  small_airport        Fulton Airport          1100         OK          ALEX   \n",
       "\n",
       "  gps_code         lon        lat  \n",
       "0      00A  -74.933601  40.070801  \n",
       "1     00AA -101.473911  38.704022  \n",
       "2     00AK -151.695999  59.949200  \n",
       "3     00AL  -86.770302  34.864799  \n",
       "4     00AS  -97.818019  34.942803  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read in data file 'airport codes.csv'\n",
    "airports_df = spark.read.option(\"header\", True).csv('airport-codes_csv.csv')\n",
    "# create a temporary views against which you can run SQL queries\n",
    "airports_df.createOrReplaceTempView(\"airports_table\")\n",
    "# read data and create a preprocessed source table for airport code data\n",
    "airports_source_table = spark.sql('''\n",
    "        SELECT type, name, CAST(elevation_ft AS LONG) elevation_ft, SPLIT(iso_region, '-')[1] iso_region,\n",
    "                UPPER(municipality) municipality, gps_code, CAST(SPLIT(coordinates,',')[0] AS DOUBLE) lon, CAST(SPLIT(coordinates,',')[1] AS DOUBLE) lat\n",
    "        FROM airports_table a\n",
    "        WHERE iso_country = 'US' AND type != 'closed'\n",
    "''')\n",
    "airports_source_table.createOrReplaceTempView(\"airports_source_table\")\n",
    "# convert to pandas df and display first 5 rows\n",
    "display(spark.sql('''\n",
    "        SELECT *\n",
    "        FROM airports_source_table\n",
    "        LIMIT 5\n",
    "''').toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We can use **iso_region** and **municipality** to link this data set with points of entry and main immigration dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**World Temperature Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Let's load first five rows from source csv file and make schema suitable for subsequent processing and joining with other sources.\n",
    "\n",
    "For the purposes of the data model we'll limit records only to USA and records since 1960."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>avg_temperature</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1960-01-01</td>\n",
       "      <td>1960</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.243</td>\n",
       "      <td>ABILENE</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>-100.53</td>\n",
       "      <td>32.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1960-02-01</td>\n",
       "      <td>1960</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4.995</td>\n",
       "      <td>ABILENE</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>-100.53</td>\n",
       "      <td>32.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1960-03-01</td>\n",
       "      <td>1960</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8.575</td>\n",
       "      <td>ABILENE</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>-100.53</td>\n",
       "      <td>32.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1960-04-01</td>\n",
       "      <td>1960</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>18.452</td>\n",
       "      <td>ABILENE</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>-100.53</td>\n",
       "      <td>32.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1960-05-01</td>\n",
       "      <td>1960</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>21.709</td>\n",
       "      <td>ABILENE</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>-100.53</td>\n",
       "      <td>32.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  year  month  day  avg_temperature     city        country  \\\n",
       "0  1960-01-01  1960      1    1            5.243  ABILENE  UNITED STATES   \n",
       "1  1960-02-01  1960      2    1            4.995  ABILENE  UNITED STATES   \n",
       "2  1960-03-01  1960      3    1            8.575  ABILENE  UNITED STATES   \n",
       "3  1960-04-01  1960      4    1           18.452  ABILENE  UNITED STATES   \n",
       "4  1960-05-01  1960      5    1           21.709  ABILENE  UNITED STATES   \n",
       "\n",
       "      lon    lat  \n",
       "0 -100.53  32.95  \n",
       "1 -100.53  32.95  \n",
       "2 -100.53  32.95  \n",
       "3 -100.53  32.95  \n",
       "4 -100.53  32.95  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read in data file 'GlobalLandTemperaturesByCity.csv'\n",
    "weather_df = spark.read.option(\"header\", True).csv('../../data2/GlobalLandTemperaturesByCity.csv')\n",
    "# create a temporary views against which you can run SQL queries\n",
    "weather_df.createOrReplaceTempView(\"weather_table\")\n",
    "# read data and create a preprocessed source table for world temperature data\n",
    "weather_source_table = spark.sql('''\n",
    "        SELECT CAST(dt AS DATE) dt, YEAR(CAST(dt AS DATE)) year, MONTH(CAST(dt AS DATE)) month, DAY(CAST(dt AS DATE)) day, CAST(AverageTemperature AS DOUBLE) avg_temperature,\n",
    "        UPPER(city) city, UPPER(country) country, CAST(SUBSTRING(longitude,1,LENGTH(longitude)-1) AS DOUBLE)*-1 lon, CAST(SUBSTRING(latitude,1,LENGTH(latitude)-1) AS DOUBLE) lat\n",
    "        FROM weather_table w\n",
    "        WHERE country = 'United States' AND YEAR(CAST(dt AS DATE)) >= 1960\n",
    "''')\n",
    "weather_source_table.createOrReplaceTempView(\"weather_source_table\")\n",
    "# convert to pandas df and display first 5 rows\n",
    "display(spark.sql('''\n",
    "        SELECT *\n",
    "        FROM weather_source_table\n",
    "        LIMIT 5\n",
    "''').toPandas())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We can try to link entry events from main dataset with these average monthly temperatures using **year**, **month** and **city**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Save source tables in the data lake**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Let's save the preprocessed source tables in our data lake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# State your output s3 bucket for source data and processed fact and dimension tables \n",
    "output_data = \"\"\n",
    "\n",
    "#write to parquet\n",
    "i94_full_source_table.write.partitionBy('year', 'month').mode('overwrite').\\\n",
    "                    parquet(output_data + 'source/i94/i94_records.parquet')\n",
    "\n",
    "cities_pop_source_table.write.partitionBy('state_code').mode('overwrite').\\\n",
    "                    parquet(output_data + 'source/demographic/demographic.parquet')\n",
    "\n",
    "weather_source_table.write.partitionBy('year', 'month').mode('overwrite').\\\n",
    "                    parquet(output_data + 'source/weather/weather.parquet')\n",
    "\n",
    "airports_source_table.write.partitionBy('iso_region').mode('overwrite').\\\n",
    "                    parquet(output_data + 'source/airports/airports.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Let's explore our data in more detail.\n",
    "\n",
    "In this step we'll prepare our data for trnasforming in the target data model and complete the following steps:\n",
    "1. Identify and drop missing values\n",
    "2. Identify primary and foreign keys for fact and dimension tables and eliminate duplicate data for them by grouping, averaging, etc.\n",
    "\n",
    "In the previous step we already reduced the size of datasets dropping out irrelevant records.\n",
    "\n",
    "#### Cleaning Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**I94 Immigration Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Let's check full dataset for null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                             0\n",
       "country_of_residence           0\n",
       "country_of_citizenship         0\n",
       "city_of_entry                  0\n",
       "state_of_entry_code            0\n",
       "state_of_entry_full            0\n",
       "border_cross_method            0\n",
       "type_of_visa                   0\n",
       "class_of_admission             0\n",
       "gender                    339908\n",
       "age                          174\n",
       "arr_date                       0\n",
       "dep_date                  109375\n",
       "year                           0\n",
       "month                          0\n",
       "day                            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94_full_source_table.toPandas().isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We can see that most important fields for linking with other datasets - **arr_date**, **state_of_entry_code**, **city_of_entry** - don't have missing values.\n",
    "\n",
    "Missing values in **gender**, **age** and **dep_date** we'll leave as is.\n",
    "\n",
    "Other missing values in **country_name**, **city_of_entry**, **border_cross_method**, **type_of_visa**, etc. we've alredy dropped in the previous stage.\n",
    "\n",
    "Now let's check wether we can use **id** field as primary key for our future fact table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2515336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_ids\n",
       "0    2515336"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(spark.sql('''\n",
    "        SELECT COUNT(c.id) total_ids\n",
    "        FROM i94_source_table c\n",
    "''').toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2515336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_ids\n",
       "0     2515336"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(spark.sql('''\n",
    "        SELECT COUNT(DISTINCT c.id) unique_ids\n",
    "        FROM i94_source_table c\n",
    "''').toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "As we can see **id** field doesn't contain duplicate values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Finally let's check the consistency of **arr_date** and **dep_date** fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count(1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count(1)\n",
       "0       180"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(spark.sql('''\n",
    "        SELECT COUNT(*)\n",
    "        FROM i94_source_table c\n",
    "        WHERE dep_date < arr_date\n",
    "''').toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arr_date</th>\n",
       "      <th>dep_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-04-02</td>\n",
       "      <td>2016-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-04-02</td>\n",
       "      <td>2016-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-04-02</td>\n",
       "      <td>2016-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-04-02</td>\n",
       "      <td>2016-01-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     arr_date    dep_date\n",
       "0  2016-04-01  2016-03-31\n",
       "1  2016-04-02  2016-03-19\n",
       "2  2016-04-02  2016-01-26\n",
       "3  2016-04-02  2016-04-01\n",
       "4  2016-04-02  2016-01-31"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(spark.sql('''\n",
    "        SELECT arr_date, dep_date\n",
    "        FROM i94_source_table c\n",
    "        WHERE dep_date < arr_date\n",
    "        LIMIT 5\n",
    "''').toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We'll drop these records and form final preprocessed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_num_of_records</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2515156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_num_of_records\n",
       "0               2515156"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i94_full_source_table = spark.sql('''\n",
    "        SELECT *\n",
    "        FROM i94_source_table i\n",
    "        WHERE dep_date IS NULL OR dep_date >= arr_date\n",
    "''')\n",
    "i94_full_source_table.createOrReplaceTempView(\"i94_source_table\")\n",
    "\n",
    "display(spark.sql('''\n",
    "        SELECT COUNT(*) total_num_of_records\n",
    "        FROM i94_source_table a\n",
    "''').toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>country_of_residence</th>\n",
       "      <th>country_of_citizenship</th>\n",
       "      <th>city_of_entry</th>\n",
       "      <th>state_of_entry_code</th>\n",
       "      <th>state_of_entry_full</th>\n",
       "      <th>border_cross_method</th>\n",
       "      <th>type_of_visa</th>\n",
       "      <th>class_of_admission</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>arr_date</th>\n",
       "      <th>dep_date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>ALBANIA</td>\n",
       "      <td>ALBANIA</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>Air</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>B2</td>\n",
       "      <td>None</td>\n",
       "      <td>28</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>ALBANIA</td>\n",
       "      <td>ALBANIA</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>Air</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>B2</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>ALBANIA</td>\n",
       "      <td>ALBANIA</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>Air</td>\n",
       "      <td>Business</td>\n",
       "      <td>B1</td>\n",
       "      <td>None</td>\n",
       "      <td>57</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-11</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>ALBANIA</td>\n",
       "      <td>ALBANIA</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>Air</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>B2</td>\n",
       "      <td>None</td>\n",
       "      <td>63</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-14</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>ALBANIA</td>\n",
       "      <td>ALBANIA</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>Air</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>B2</td>\n",
       "      <td>None</td>\n",
       "      <td>57</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-14</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id country_of_residence country_of_citizenship city_of_entry  \\\n",
       "0  16              ALBANIA                ALBANIA      NEW YORK   \n",
       "1  17              ALBANIA                ALBANIA      NEW YORK   \n",
       "2  18              ALBANIA                ALBANIA      NEW YORK   \n",
       "3  19              ALBANIA                ALBANIA      NEW YORK   \n",
       "4  20              ALBANIA                ALBANIA      NEW YORK   \n",
       "\n",
       "  state_of_entry_code state_of_entry_full border_cross_method type_of_visa  \\\n",
       "0                  NY            NEW YORK                 Air     Pleasure   \n",
       "1                  NY            NEW YORK                 Air     Pleasure   \n",
       "2                  NY            NEW YORK                 Air     Business   \n",
       "3                  NY            NEW YORK                 Air     Pleasure   \n",
       "4                  NY            NEW YORK                 Air     Pleasure   \n",
       "\n",
       "  class_of_admission gender  age    arr_date    dep_date  year  month  day  \n",
       "0                 B2   None   28  2016-04-01  2016-04-23  2016      4    1  \n",
       "1                 B2   None    4  2016-04-01  2016-04-23  2016      4    1  \n",
       "2                 B1   None   57  2016-04-01  2016-04-11  2016      4    1  \n",
       "3                 B2   None   63  2016-04-01  2016-04-14  2016      4    1  \n",
       "4                 B2   None   57  2016-04-01  2016-04-14  2016      4    1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(spark.sql('''\n",
    "        SELECT *\n",
    "        FROM i94_source_table c\n",
    "        LIMIT 5\n",
    "''').toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**U.S. City Demographic Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_num_of_records</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_num_of_records\n",
       "0                  2891"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(spark.sql('''\n",
    "        SELECT COUNT(*) total_num_of_records\n",
    "        FROM cities_pop_source_table c\n",
    "''').toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Let's check for null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city                   0\n",
       "state                  0\n",
       "median_age             0\n",
       "male_population        3\n",
       "female_population      3\n",
       "total_population       0\n",
       "number_of_veterans    13\n",
       "foreign_born          13\n",
       "avg_household_size    16\n",
       "state_code             0\n",
       "race                   0\n",
       "count                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_pop_source_table.toPandas().isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Since selected key fields have no missing values we'll leave other fields as is.\n",
    "\n",
    "Missing values are present in various statistics fields across the table. This problem will be solved during building analytics reports based on fact and dimension tables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Now we check if the combination of city and state doesn't contain duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOLINGBROOK</td>\n",
       "      <td>ILLINOIS</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WESTMINSTER</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LITTLE ROCK</td>\n",
       "      <td>ARKANSAS</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DECATUR</td>\n",
       "      <td>ILLINOIS</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>THE WOODLANDS</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            city       state  cnt\n",
       "0    BOLINGBROOK    ILLINOIS    5\n",
       "1    WESTMINSTER  CALIFORNIA    5\n",
       "2    LITTLE ROCK    ARKANSAS    5\n",
       "3        DECATUR    ILLINOIS    5\n",
       "4  THE WOODLANDS       TEXAS    5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(spark.sql('''\n",
    "        SELECT city, state, COUNT(*) cnt\n",
    "        FROM cities_pop_source_table c\n",
    "        GROUP BY city, state\n",
    "        HAVING COUNT(*) > 1\n",
    "        LIMIT 5\n",
    "''').toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>median_age</th>\n",
       "      <th>male_population</th>\n",
       "      <th>female_population</th>\n",
       "      <th>total_population</th>\n",
       "      <th>number_of_veterans</th>\n",
       "      <th>foreign_born</th>\n",
       "      <th>avg_household_size</th>\n",
       "      <th>state_code</th>\n",
       "      <th>race</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOLINGBROOK</td>\n",
       "      <td>ILLINOIS</td>\n",
       "      <td>33.7</td>\n",
       "      <td>36295</td>\n",
       "      <td>35801</td>\n",
       "      <td>72096</td>\n",
       "      <td>2951</td>\n",
       "      <td>15212</td>\n",
       "      <td>3.42</td>\n",
       "      <td>IL</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BOLINGBROOK</td>\n",
       "      <td>ILLINOIS</td>\n",
       "      <td>33.7</td>\n",
       "      <td>36295</td>\n",
       "      <td>35801</td>\n",
       "      <td>72096</td>\n",
       "      <td>2951</td>\n",
       "      <td>15212</td>\n",
       "      <td>3.42</td>\n",
       "      <td>IL</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>12671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOLINGBROOK</td>\n",
       "      <td>ILLINOIS</td>\n",
       "      <td>33.7</td>\n",
       "      <td>36295</td>\n",
       "      <td>35801</td>\n",
       "      <td>72096</td>\n",
       "      <td>2951</td>\n",
       "      <td>15212</td>\n",
       "      <td>3.42</td>\n",
       "      <td>IL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>9788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOLINGBROOK</td>\n",
       "      <td>ILLINOIS</td>\n",
       "      <td>33.7</td>\n",
       "      <td>36295</td>\n",
       "      <td>35801</td>\n",
       "      <td>72096</td>\n",
       "      <td>2951</td>\n",
       "      <td>15212</td>\n",
       "      <td>3.42</td>\n",
       "      <td>IL</td>\n",
       "      <td>White</td>\n",
       "      <td>40458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BOLINGBROOK</td>\n",
       "      <td>ILLINOIS</td>\n",
       "      <td>33.7</td>\n",
       "      <td>36295</td>\n",
       "      <td>35801</td>\n",
       "      <td>72096</td>\n",
       "      <td>2951</td>\n",
       "      <td>15212</td>\n",
       "      <td>3.42</td>\n",
       "      <td>IL</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>16904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          city     state  median_age  male_population  female_population  \\\n",
       "0  BOLINGBROOK  ILLINOIS        33.7            36295              35801   \n",
       "1  BOLINGBROOK  ILLINOIS        33.7            36295              35801   \n",
       "2  BOLINGBROOK  ILLINOIS        33.7            36295              35801   \n",
       "3  BOLINGBROOK  ILLINOIS        33.7            36295              35801   \n",
       "4  BOLINGBROOK  ILLINOIS        33.7            36295              35801   \n",
       "\n",
       "   total_population  number_of_veterans  foreign_born  avg_household_size  \\\n",
       "0             72096                2951         15212                3.42   \n",
       "1             72096                2951         15212                3.42   \n",
       "2             72096                2951         15212                3.42   \n",
       "3             72096                2951         15212                3.42   \n",
       "4             72096                2951         15212                3.42   \n",
       "\n",
       "  state_code                               race  count  \n",
       "0         IL  American Indian and Alaska Native    323  \n",
       "1         IL          Black or African-American  12671  \n",
       "2         IL                              Asian   9788  \n",
       "3         IL                              White  40458  \n",
       "4         IL                 Hispanic or Latino  16904  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(spark.sql('''\n",
    "        SELECT *\n",
    "        FROM cities_pop_source_table c\n",
    "        WHERE city = 'BOLINGBROOK' AND state = 'ILLINOIS'\n",
    "''').toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Black or African-American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hispanic or Latino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                race\n",
       "0          Black or African-American\n",
       "1                 Hispanic or Latino\n",
       "2                              White\n",
       "3                              Asian\n",
       "4  American Indian and Alaska Native"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(spark.sql('''\n",
    "        SELECT DISTINCT race\n",
    "        FROM cities_pop_source_table a\n",
    "''').toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "As we can see, we have distinct records for separate races. Statistics other than count field is the same for every race in given city.\n",
    "\n",
    "Let's transpose race into columns and drop duplicate rows for cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_num_of_records</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_num_of_records\n",
       "0                   596"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cities_pop_source_table = spark.sql('''\n",
    "        SELECT DISTINCT c.city city, c.state state, c.state_code state_code, c.median_age median_age, \n",
    "                        c.male_population male_population, c.female_population female_population,\n",
    "                        c.total_population total_population, c.number_of_veterans number_of_veterans,\n",
    "                        c.foreign_born foreign_born, c.avg_household_size avg_household_size,\n",
    "                        c1.american_indian_and_alaska_native american_indian_and_alaska_native,\n",
    "                        c2.asian asian, c3.white white, c4.hispanic_or_latino hispanic_or_latino,\n",
    "                        c5.black_or_african_american black_or_african_american\n",
    "        FROM cities_pop_source_table c\n",
    "        LEFT JOIN (\n",
    "            SELECT city, state, count as american_indian_and_alaska_native\n",
    "            FROM cities_pop_source_table\n",
    "            WHERE race = \"American Indian and Alaska Native\"\n",
    "        ) c1\n",
    "        ON c.city = c1.city AND c.state = c1.state\n",
    "        LEFT JOIN (\n",
    "            SELECT city, state, count as asian\n",
    "            FROM cities_pop_source_table\n",
    "            WHERE race = \"Asian\"\n",
    "        ) c2\n",
    "        ON c.city = c2.city AND c.state = c2.state\n",
    "        LEFT JOIN (\n",
    "            SELECT city, state, count as white\n",
    "            FROM cities_pop_source_table\n",
    "            WHERE race = \"White\"\n",
    "        ) c3\n",
    "        ON c.city = c3.city AND c.state = c3.state\n",
    "        LEFT JOIN (\n",
    "            SELECT city, state, count as hispanic_or_latino\n",
    "            FROM cities_pop_source_table\n",
    "            WHERE race = \"Hispanic or Latino\"\n",
    "        ) c4\n",
    "        ON c.city = c4.city AND c.state = c4.state\n",
    "        LEFT JOIN (\n",
    "            SELECT city, state, count as black_or_african_american\n",
    "            FROM cities_pop_source_table\n",
    "            WHERE race = \"Black or African-American\"\n",
    "        ) c5\n",
    "        ON c.city = c5.city AND c.state = c5.state\n",
    "''')\n",
    "cities_pop_source_table.createOrReplaceTempView(\"cities_pop_source_table\")\n",
    "\n",
    "display(spark.sql('''\n",
    "        SELECT COUNT(*) total_num_of_records\n",
    "        FROM cities_pop_source_table a\n",
    "''').toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Now we can join demographic data to other statistics based on the city and state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>state_code</th>\n",
       "      <th>median_age</th>\n",
       "      <th>male_population</th>\n",
       "      <th>female_population</th>\n",
       "      <th>total_population</th>\n",
       "      <th>number_of_veterans</th>\n",
       "      <th>foreign_born</th>\n",
       "      <th>avg_household_size</th>\n",
       "      <th>american_indian_and_alaska_native</th>\n",
       "      <th>asian</th>\n",
       "      <th>white</th>\n",
       "      <th>hispanic_or_latino</th>\n",
       "      <th>black_or_african_american</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POMPANO BEACH</td>\n",
       "      <td>FLORIDA</td>\n",
       "      <td>FL</td>\n",
       "      <td>42.5</td>\n",
       "      <td>56569</td>\n",
       "      <td>51202</td>\n",
       "      <td>107771</td>\n",
       "      <td>5145</td>\n",
       "      <td>32733</td>\n",
       "      <td>2.55</td>\n",
       "      <td>2138</td>\n",
       "      <td>1089</td>\n",
       "      <td>67360</td>\n",
       "      <td>23225</td>\n",
       "      <td>38653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAWTHORNE</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>CA</td>\n",
       "      <td>33.7</td>\n",
       "      <td>43682</td>\n",
       "      <td>44762</td>\n",
       "      <td>88444</td>\n",
       "      <td>2123</td>\n",
       "      <td>32107</td>\n",
       "      <td>2.97</td>\n",
       "      <td>906</td>\n",
       "      <td>7601</td>\n",
       "      <td>23665</td>\n",
       "      <td>50115</td>\n",
       "      <td>21566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MELBOURNE</td>\n",
       "      <td>FLORIDA</td>\n",
       "      <td>FL</td>\n",
       "      <td>43.4</td>\n",
       "      <td>39180</td>\n",
       "      <td>40956</td>\n",
       "      <td>80136</td>\n",
       "      <td>8363</td>\n",
       "      <td>9685</td>\n",
       "      <td>2.37</td>\n",
       "      <td>251</td>\n",
       "      <td>5186</td>\n",
       "      <td>65397</td>\n",
       "      <td>6060</td>\n",
       "      <td>11721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OREM</td>\n",
       "      <td>UTAH</td>\n",
       "      <td>UT</td>\n",
       "      <td>26.1</td>\n",
       "      <td>48695</td>\n",
       "      <td>45762</td>\n",
       "      <td>94457</td>\n",
       "      <td>2828</td>\n",
       "      <td>12808</td>\n",
       "      <td>3.26</td>\n",
       "      <td>976</td>\n",
       "      <td>3862</td>\n",
       "      <td>85512</td>\n",
       "      <td>18342</td>\n",
       "      <td>1837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHICAGO</td>\n",
       "      <td>ILLINOIS</td>\n",
       "      <td>IL</td>\n",
       "      <td>34.2</td>\n",
       "      <td>1320015</td>\n",
       "      <td>1400541</td>\n",
       "      <td>2720556</td>\n",
       "      <td>72042</td>\n",
       "      <td>573463</td>\n",
       "      <td>2.53</td>\n",
       "      <td>23323</td>\n",
       "      <td>195084</td>\n",
       "      <td>1374535</td>\n",
       "      <td>785725</td>\n",
       "      <td>873316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            city       state state_code  median_age  male_population  \\\n",
       "0  POMPANO BEACH     FLORIDA         FL        42.5            56569   \n",
       "1      HAWTHORNE  CALIFORNIA         CA        33.7            43682   \n",
       "2      MELBOURNE     FLORIDA         FL        43.4            39180   \n",
       "3           OREM        UTAH         UT        26.1            48695   \n",
       "4        CHICAGO    ILLINOIS         IL        34.2          1320015   \n",
       "\n",
       "   female_population  total_population  number_of_veterans  foreign_born  \\\n",
       "0              51202            107771                5145         32733   \n",
       "1              44762             88444                2123         32107   \n",
       "2              40956             80136                8363          9685   \n",
       "3              45762             94457                2828         12808   \n",
       "4            1400541           2720556               72042        573463   \n",
       "\n",
       "   avg_household_size  american_indian_and_alaska_native   asian    white  \\\n",
       "0                2.55                               2138    1089    67360   \n",
       "1                2.97                                906    7601    23665   \n",
       "2                2.37                                251    5186    65397   \n",
       "3                3.26                                976    3862    85512   \n",
       "4                2.53                              23323  195084  1374535   \n",
       "\n",
       "   hispanic_or_latino  black_or_african_american  \n",
       "0               23225                      38653  \n",
       "1               50115                      21566  \n",
       "2                6060                      11721  \n",
       "3               18342                       1837  \n",
       "4              785725                     873316  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(spark.sql('''\n",
    "        SELECT *\n",
    "        FROM cities_pop_source_table a\n",
    "        LIMIT 5\n",
    "''').toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Airport Code Table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_num_of_records</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_num_of_records\n",
       "0                 21431"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(spark.sql('''\n",
    "        SELECT COUNT(*) total_num_of_records\n",
    "        FROM airports_source_table a\n",
    "''').toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count(type)</th>\n",
       "      <th>count(name)</th>\n",
       "      <th>count(iso_region)</th>\n",
       "      <th>count(municipality)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count(type)  count(name)  count(iso_region)  count(municipality)\n",
       "0           67           67                 67                    0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(spark.sql('''\n",
    "        SELECT COUNT(type), COUNT(name), COUNT(iso_region), COUNT(municipality)\n",
    "        FROM airports_source_table a\n",
    "        WHERE type is NULL OR name is NULL OR iso_region is NULL OR municipality is NULL\n",
    "''').toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>heliport</td>\n",
       "      <td>Watertown / Brownlee Heliport</td>\n",
       "      <td>1720.0</td>\n",
       "      <td>SD</td>\n",
       "      <td>None</td>\n",
       "      <td>15SD</td>\n",
       "      <td>-97.108090</td>\n",
       "      <td>44.883265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>heliport</td>\n",
       "      <td>Nordman / Phillabaum Heliport</td>\n",
       "      <td>2440.0</td>\n",
       "      <td>ID</td>\n",
       "      <td>None</td>\n",
       "      <td>21ID</td>\n",
       "      <td>-116.871175</td>\n",
       "      <td>48.631483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seaplane_base</td>\n",
       "      <td>Peru / Destiny Cove SPB</td>\n",
       "      <td>580.0</td>\n",
       "      <td>ME</td>\n",
       "      <td>None</td>\n",
       "      <td>3ME7</td>\n",
       "      <td>-70.396957</td>\n",
       "      <td>44.460597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>small_airport</td>\n",
       "      <td>Zadow Airstrip</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TX</td>\n",
       "      <td>None</td>\n",
       "      <td>6XA4</td>\n",
       "      <td>-95.954354</td>\n",
       "      <td>29.991739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>small_airport</td>\n",
       "      <td>Gun Barrel City Airpark</td>\n",
       "      <td>385.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>None</td>\n",
       "      <td>74XA</td>\n",
       "      <td>-96.145665</td>\n",
       "      <td>32.355150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            type                           name  elevation_ft iso_region  \\\n",
       "0       heliport  Watertown / Brownlee Heliport        1720.0         SD   \n",
       "1       heliport  Nordman / Phillabaum Heliport        2440.0         ID   \n",
       "2  seaplane_base        Peru / Destiny Cove SPB         580.0         ME   \n",
       "3  small_airport                 Zadow Airstrip           NaN         TX   \n",
       "4  small_airport        Gun Barrel City Airpark         385.0         TX   \n",
       "\n",
       "  municipality gps_code         lon        lat  \n",
       "0         None     15SD  -97.108090  44.883265  \n",
       "1         None     21ID -116.871175  48.631483  \n",
       "2         None     3ME7  -70.396957  44.460597  \n",
       "3         None     6XA4  -95.954354  29.991739  \n",
       "4         None     74XA  -96.145665  32.355150  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(spark.sql('''\n",
    "        SELECT *\n",
    "        FROM airports_source_table a\n",
    "        WHERE municipality is NULL\n",
    "        LIMIT 5\n",
    "''').toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Source dataset contains 67 missing values in **municipality** field. Let's drop these records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_num_of_records</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_num_of_records\n",
       "0                 21364"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "airports_source_table = spark.sql('''\n",
    "        SELECT *\n",
    "        FROM airports_source_table a\n",
    "        WHERE municipality IS NOT NULL\n",
    "''')\n",
    "airports_source_table.createOrReplaceTempView(\"airports_source_table\")\n",
    "\n",
    "display(spark.sql('''\n",
    "        SELECT COUNT(*) total_num_of_records\n",
    "        FROM airports_source_table a\n",
    "''').toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Now we check if the combination of municipality and iso_region doesn't contain duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TX</td>\n",
       "      <td>PEARLAND</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NM</td>\n",
       "      <td>RESERVE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SD</td>\n",
       "      <td>CUSTER</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VA</td>\n",
       "      <td>BEDFORD</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MT</td>\n",
       "      <td>HELENA</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  iso_region municipality  cnt\n",
       "0         TX     PEARLAND    9\n",
       "1         NM      RESERVE    2\n",
       "2         SD       CUSTER    5\n",
       "3         VA      BEDFORD    6\n",
       "4         MT       HELENA    9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(spark.sql('''\n",
    "        SELECT iso_region, municipality, COUNT(*) cnt\n",
    "        FROM airports_source_table a\n",
    "        GROUP BY iso_region, municipality\n",
    "        HAVING COUNT(*) > 1\n",
    "        LIMIT 5\n",
    "''').toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "As we can see, cities often have more than one airport. So we can't use iso_region and municipality as the key for joining to other tables for now.\n",
    "\n",
    "We'll transform this dataset to the new schema later (afer cleaning world temperature data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**World Temperature Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_num_of_records</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_num_of_records\n",
       "0                165765"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(spark.sql('''\n",
    "        SELECT COUNT(*) total_num_of_records\n",
    "        FROM weather_source_table w\n",
    "''').toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Let's test dataset for null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count(dt)</th>\n",
       "      <th>count(avg_temperature)</th>\n",
       "      <th>count(city)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count(dt)  count(avg_temperature)  count(city)\n",
       "0          1                       0            1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(spark.sql('''\n",
    "        SELECT COUNT(dt), COUNT(avg_temperature), COUNT(city)\n",
    "        FROM weather_source_table w\n",
    "        WHERE dt is NULL OR avg_temperature is NULL OR city is NULL\n",
    "''').toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>avg_temperature</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-09-01</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>ANCHORAGE</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>-151.13</td>\n",
       "      <td>61.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  year  month  day avg_temperature       city        country  \\\n",
       "0  2013-09-01  2013      9    1            None  ANCHORAGE  UNITED STATES   \n",
       "\n",
       "      lon    lat  \n",
       "0 -151.13  61.88  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(spark.sql('''\n",
    "        SELECT *\n",
    "        FROM weather_source_table w\n",
    "        WHERE avg_temperature is NULL\n",
    "''').toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Source dataset contains one missing value in **avg_temperature** field. Let's drop this record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_num_of_records</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_num_of_records\n",
       "0                165764"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weather_source_table = spark.sql('''\n",
    "        SELECT *\n",
    "        FROM weather_source_table w\n",
    "        WHERE avg_temperature IS NOT NULL\n",
    "''')\n",
    "weather_source_table.createOrReplaceTempView(\"weather_source_table\")\n",
    "\n",
    "display(spark.sql('''\n",
    "        SELECT COUNT(*) total_num_of_records\n",
    "        FROM weather_source_table w\n",
    "''').toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Now we'll check if the combination of city and date doesn't contain duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>city</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1961-08-01</td>\n",
       "      <td>ARLINGTON</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-06-01</td>\n",
       "      <td>ARLINGTON</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1981-04-01</td>\n",
       "      <td>AURORA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1991-03-01</td>\n",
       "      <td>AURORA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1966-10-01</td>\n",
       "      <td>COLUMBUS</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt       city  cnt\n",
       "0  1961-08-01  ARLINGTON    2\n",
       "1  2010-06-01  ARLINGTON    2\n",
       "2  1981-04-01     AURORA    2\n",
       "3  1991-03-01     AURORA    2\n",
       "4  1966-10-01   COLUMBUS    2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(spark.sql('''\n",
    "        SELECT dt, city, COUNT(*) cnt\n",
    "        FROM weather_source_table w\n",
    "        GROUP BY dt, city\n",
    "        HAVING COUNT(*) > 1\n",
    "        LIMIT 5\n",
    "''').toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>city</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1961-08-01</td>\n",
       "      <td>ARLINGTON</td>\n",
       "      <td>32.95</td>\n",
       "      <td>-96.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1961-08-01</td>\n",
       "      <td>ARLINGTON</td>\n",
       "      <td>39.38</td>\n",
       "      <td>-76.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt       city    lat    lon\n",
       "0  1961-08-01  ARLINGTON  32.95 -96.70\n",
       "1  1961-08-01  ARLINGTON  39.38 -76.99"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(spark.sql('''\n",
    "        SELECT dt, city, lat, lon\n",
    "        FROM weather_source_table w\n",
    "        WHERE city = 'ARLINGTON' AND dt = '1961-08-01'\n",
    "''').toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "As we can see from lat-lon reference there are two different cities with the same name in different states.\n",
    "\n",
    "Let's repeat check using latitude and longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>city</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [dt, city, lat, lon, cnt]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(spark.sql('''\n",
    "        SELECT dt, city, lat, lon, COUNT(*) cnt\n",
    "        FROM weather_source_table w\n",
    "        GROUP BY dt, city, lat, lon\n",
    "        HAVING COUNT(*) > 1\n",
    "        LIMIT 5\n",
    "''').toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Now we can see that there is no duplicate records.\n",
    "\n",
    "But we must find the way to link city name with state name if we want to link this dataset to other sources.\n",
    "\n",
    "Let's try find the distance between every city and every airport using geo-ref. If the distance less than some threshold we'll link records in both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "tmp_loc_table = spark.sql('''\n",
    "        SELECT DISTINCT w.city city, w.lat lat, w.lon lon\n",
    "        FROM weather_source_table w\n",
    "''')\n",
    "tmp_loc_table.createOrReplaceTempView(\"tmp_loc_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Take a closer look at the city of Philadelphia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>municipality</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>name</th>\n",
       "      <th>airport_lon</th>\n",
       "      <th>airport_lat</th>\n",
       "      <th>dist_to_airport</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>-74.91</td>\n",
       "      <td>39.38</td>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>PA</td>\n",
       "      <td>Sports Complex N Lot Heliport</td>\n",
       "      <td>-75.161344</td>\n",
       "      <td>39.901544</td>\n",
       "      <td>0.578949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>-74.91</td>\n",
       "      <td>39.38</td>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>PA</td>\n",
       "      <td>Peco Oregon Shop Heliport</td>\n",
       "      <td>-75.139900</td>\n",
       "      <td>39.912601</td>\n",
       "      <td>0.580102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>-74.91</td>\n",
       "      <td>39.38</td>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>PA</td>\n",
       "      <td>S &amp; C Distribution Center Heliport</td>\n",
       "      <td>-75.228798</td>\n",
       "      <td>39.879299</td>\n",
       "      <td>0.592395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>-74.91</td>\n",
       "      <td>39.38</td>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>PA</td>\n",
       "      <td>Philadelphia International Airport</td>\n",
       "      <td>-75.241096</td>\n",
       "      <td>39.871899</td>\n",
       "      <td>0.592950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>-74.91</td>\n",
       "      <td>39.38</td>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>PA</td>\n",
       "      <td>Penn's Landing Heliport</td>\n",
       "      <td>-75.141296</td>\n",
       "      <td>39.937302</td>\n",
       "      <td>0.603393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>-74.91</td>\n",
       "      <td>39.38</td>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>PA</td>\n",
       "      <td>Federal Reserve Bank Heliport</td>\n",
       "      <td>-75.150497</td>\n",
       "      <td>39.936798</td>\n",
       "      <td>0.606517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>-74.91</td>\n",
       "      <td>39.38</td>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>PA</td>\n",
       "      <td>Atlantic Refining &amp; Marketing Corp Heliport</td>\n",
       "      <td>-75.196602</td>\n",
       "      <td>39.919800</td>\n",
       "      <td>0.611166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>-74.91</td>\n",
       "      <td>39.38</td>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>PA</td>\n",
       "      <td>Thomas Jefferson University Hospital Heliport</td>\n",
       "      <td>-75.158501</td>\n",
       "      <td>39.949001</td>\n",
       "      <td>0.620899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>-74.91</td>\n",
       "      <td>39.38</td>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>PA</td>\n",
       "      <td>S &amp; C 8th &amp; Market Helistop</td>\n",
       "      <td>-75.149597</td>\n",
       "      <td>39.953400</td>\n",
       "      <td>0.621445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>-74.91</td>\n",
       "      <td>39.38</td>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>PA</td>\n",
       "      <td>Hahnemann Heliport</td>\n",
       "      <td>-75.162697</td>\n",
       "      <td>39.957100</td>\n",
       "      <td>0.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>-74.91</td>\n",
       "      <td>39.38</td>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>PA</td>\n",
       "      <td>Hospital of Univ. of Pa Heliport</td>\n",
       "      <td>-75.194099</td>\n",
       "      <td>39.945900</td>\n",
       "      <td>0.633210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>-74.91</td>\n",
       "      <td>39.38</td>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>PA</td>\n",
       "      <td>PECO Mob. Heliport</td>\n",
       "      <td>-75.178201</td>\n",
       "      <td>39.954800</td>\n",
       "      <td>0.634292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>-74.91</td>\n",
       "      <td>39.38</td>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>PA</td>\n",
       "      <td>Childrens Hospital Of Philadelphia Heliport</td>\n",
       "      <td>-75.196111</td>\n",
       "      <td>39.947222</td>\n",
       "      <td>0.635295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>-74.91</td>\n",
       "      <td>39.38</td>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>PA</td>\n",
       "      <td>Children's Hospital Heliport</td>\n",
       "      <td>-75.194298</td>\n",
       "      <td>39.948200</td>\n",
       "      <td>0.635356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>-74.91</td>\n",
       "      <td>39.38</td>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>PA</td>\n",
       "      <td>Core States - 1st Pa Heliport</td>\n",
       "      <td>-75.191299</td>\n",
       "      <td>39.958401</td>\n",
       "      <td>0.643177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            city    lon    lat  municipality iso_region  \\\n",
       "0   PHILADELPHIA -74.91  39.38  PHILADELPHIA         PA   \n",
       "1   PHILADELPHIA -74.91  39.38  PHILADELPHIA         PA   \n",
       "2   PHILADELPHIA -74.91  39.38  PHILADELPHIA         PA   \n",
       "3   PHILADELPHIA -74.91  39.38  PHILADELPHIA         PA   \n",
       "4   PHILADELPHIA -74.91  39.38  PHILADELPHIA         PA   \n",
       "5   PHILADELPHIA -74.91  39.38  PHILADELPHIA         PA   \n",
       "6   PHILADELPHIA -74.91  39.38  PHILADELPHIA         PA   \n",
       "7   PHILADELPHIA -74.91  39.38  PHILADELPHIA         PA   \n",
       "8   PHILADELPHIA -74.91  39.38  PHILADELPHIA         PA   \n",
       "9   PHILADELPHIA -74.91  39.38  PHILADELPHIA         PA   \n",
       "10  PHILADELPHIA -74.91  39.38  PHILADELPHIA         PA   \n",
       "11  PHILADELPHIA -74.91  39.38  PHILADELPHIA         PA   \n",
       "12  PHILADELPHIA -74.91  39.38  PHILADELPHIA         PA   \n",
       "13  PHILADELPHIA -74.91  39.38  PHILADELPHIA         PA   \n",
       "14  PHILADELPHIA -74.91  39.38  PHILADELPHIA         PA   \n",
       "\n",
       "                                             name  airport_lon  airport_lat  \\\n",
       "0                   Sports Complex N Lot Heliport   -75.161344    39.901544   \n",
       "1                       Peco Oregon Shop Heliport   -75.139900    39.912601   \n",
       "2              S & C Distribution Center Heliport   -75.228798    39.879299   \n",
       "3              Philadelphia International Airport   -75.241096    39.871899   \n",
       "4                         Penn's Landing Heliport   -75.141296    39.937302   \n",
       "5                   Federal Reserve Bank Heliport   -75.150497    39.936798   \n",
       "6     Atlantic Refining & Marketing Corp Heliport   -75.196602    39.919800   \n",
       "7   Thomas Jefferson University Hospital Heliport   -75.158501    39.949001   \n",
       "8                     S & C 8th & Market Helistop   -75.149597    39.953400   \n",
       "9                              Hahnemann Heliport   -75.162697    39.957100   \n",
       "10               Hospital of Univ. of Pa Heliport   -75.194099    39.945900   \n",
       "11                             PECO Mob. Heliport   -75.178201    39.954800   \n",
       "12    Childrens Hospital Of Philadelphia Heliport   -75.196111    39.947222   \n",
       "13                   Children's Hospital Heliport   -75.194298    39.948200   \n",
       "14                  Core States - 1st Pa Heliport   -75.191299    39.958401   \n",
       "\n",
       "    dist_to_airport  \n",
       "0          0.578949  \n",
       "1          0.580102  \n",
       "2          0.592395  \n",
       "3          0.592950  \n",
       "4          0.603393  \n",
       "5          0.606517  \n",
       "6          0.611166  \n",
       "7          0.620899  \n",
       "8          0.621445  \n",
       "9          0.630000  \n",
       "10         0.633210  \n",
       "11         0.634292  \n",
       "12         0.635295  \n",
       "13         0.635356  \n",
       "14         0.643177  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(spark.sql('''\n",
    "        SELECT w1.city, w1.lon, w1.lat, a.municipality, a.iso_region, a.name, a.lon airport_lon, a.lat airport_lat,\n",
    "        SQRT((w1.lat-a.lat)*(w1.lat-a.lat)+(w1.lon-a.lon)*(w1.lon-a.lon)) dist_to_airport\n",
    "        FROM tmp_loc_table w1\n",
    "        JOIN airports_source_table a\n",
    "        ON w1.city = a.municipality\n",
    "        WHERE w1.city = 'PHILADELPHIA'\n",
    "        ORDER BY dist_to_airport\n",
    "        LIMIT 15\n",
    "''').toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Example above shows that we can use this approach to determine the state code for given city name.\n",
    "\n",
    "Cities that doesn't have matching records in airports dataset can be dropped as irrelevant to immigration flows analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>PA</td>\n",
       "      <td>39.38</td>\n",
       "      <td>-74.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           city state    lat    lon\n",
       "0  PHILADELPHIA    PA  39.38 -74.91"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DISTANCE_THRESHOLD = 1\n",
    "tmp_loc_table = spark.sql(f'''\n",
    "        SELECT DISTINCT w1.city city, a.iso_region state, w1.lat lat, w1.lon lon\n",
    "        FROM tmp_loc_table w1\n",
    "        JOIN airports_source_table a\n",
    "        ON SQRT((w1.lat-a.lat)*(w1.lat-a.lat)+(w1.lon-a.lon)*(w1.lon-a.lon)) < {DISTANCE_THRESHOLD} AND w1.city = a.municipality\n",
    "''')\n",
    "tmp_loc_table.createOrReplaceTempView(\"tmp_loc_table\")\n",
    "\n",
    "display(spark.sql('''\n",
    "        SELECT *\n",
    "        FROM tmp_loc_table w1\n",
    "        WHERE w1.city = 'PHILADELPHIA'\n",
    "        LIMIT 5\n",
    "''').toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Now we can link state code to the main temperature dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>avg_temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1960-01-01</td>\n",
       "      <td>1960</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MOBILE</td>\n",
       "      <td>AL</td>\n",
       "      <td>31.35</td>\n",
       "      <td>-88.59</td>\n",
       "      <td>8.497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1960-02-01</td>\n",
       "      <td>1960</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>MOBILE</td>\n",
       "      <td>AL</td>\n",
       "      <td>31.35</td>\n",
       "      <td>-88.59</td>\n",
       "      <td>8.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1960-03-01</td>\n",
       "      <td>1960</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>MOBILE</td>\n",
       "      <td>AL</td>\n",
       "      <td>31.35</td>\n",
       "      <td>-88.59</td>\n",
       "      <td>10.549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1960-04-01</td>\n",
       "      <td>1960</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>MOBILE</td>\n",
       "      <td>AL</td>\n",
       "      <td>31.35</td>\n",
       "      <td>-88.59</td>\n",
       "      <td>19.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1960-05-01</td>\n",
       "      <td>1960</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>MOBILE</td>\n",
       "      <td>AL</td>\n",
       "      <td>31.35</td>\n",
       "      <td>-88.59</td>\n",
       "      <td>20.958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  year  month  day    city state    lat    lon  avg_temperature\n",
       "0  1960-01-01  1960      1    1  MOBILE    AL  31.35 -88.59            8.497\n",
       "1  1960-02-01  1960      2    1  MOBILE    AL  31.35 -88.59            8.325\n",
       "2  1960-03-01  1960      3    1  MOBILE    AL  31.35 -88.59           10.549\n",
       "3  1960-04-01  1960      4    1  MOBILE    AL  31.35 -88.59           19.022\n",
       "4  1960-05-01  1960      5    1  MOBILE    AL  31.35 -88.59           20.958"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weather_source_table = spark.sql('''\n",
    "        SELECT w.dt dt, w.year year, w.month month, w.day day, w.city, w1.state,\n",
    "        w.lat, w.lon, AVG(w.avg_temperature) avg_temperature\n",
    "        FROM weather_source_table w\n",
    "        JOIN tmp_loc_table w1\n",
    "        ON w.city = w1.city AND w.lat = w1.lat AND w.lon = w1.lon\n",
    "        GROUP BY w.dt, w.year, w.month, w.day, w.city, w1.state, w.lat, w.lon    \n",
    "''')\n",
    "weather_source_table.createOrReplaceTempView(\"weather_source_table\")\n",
    "\n",
    "display(spark.sql('''\n",
    "        SELECT *\n",
    "        FROM weather_source_table w\n",
    "        LIMIT 5\n",
    "''').toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_num_of_records</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>139320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_num_of_records\n",
       "0                139320"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(spark.sql('''\n",
    "        SELECT COUNT(*) total_num_of_records\n",
    "        FROM weather_source_table w\n",
    "''').toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Now let's transform airport dataset into the new schema - number of airports per city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_num_of_records</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_num_of_records\n",
       "0                 11510"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "airports_source_table = spark.sql('''\n",
    "        SELECT iso_region, municipality, COUNT(*) number_of_airports\n",
    "        FROM airports_source_table a\n",
    "        GROUP BY iso_region, municipality\n",
    "''')\n",
    "airports_source_table.createOrReplaceTempView(\"airports_source_table\")\n",
    "\n",
    "display(spark.sql('''\n",
    "        SELECT COUNT(*) total_num_of_records\n",
    "        FROM airports_source_table a\n",
    "''').toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Now we can join the total number of airports at the point of entry to other statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>number_of_airports</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TX</td>\n",
       "      <td>PEARLAND</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NM</td>\n",
       "      <td>RESERVE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SD</td>\n",
       "      <td>CUSTER</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VA</td>\n",
       "      <td>BEDFORD</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MI</td>\n",
       "      <td>FRASER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  iso_region municipality  number_of_airports\n",
       "0         TX     PEARLAND                   9\n",
       "1         NM      RESERVE                   2\n",
       "2         SD       CUSTER                   5\n",
       "3         VA      BEDFORD                   6\n",
       "4         MI       FRASER                   1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(spark.sql('''\n",
    "        SELECT *\n",
    "        FROM airports_source_table a\n",
    "        LIMIT 5\n",
    "''').toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "For this project, we use a star schema optimized for queries on immigration analysis.\n",
    "According to the selected schema we'll build one fact table which contains measures for the immigration data and several dimension tables which contain attributes describing our target entities.\n",
    "\n",
    "For our fact table - **fact_i94_history** - we'll take i94 immigration data records and combine them with average temperatures in the city of entry for the month of the arrival event.\n",
    "\n",
    "We will use two dimensions of aggregation for our fact data:\n",
    "1. **dim_time** - timestamps of records in our **fact_i94_history** table broken down into specific units (day, week, month, year, etc.)\n",
    "2. **dim_cities** - List of the U.S. cities with the most important statistical attributes on them (demography, number of airports, etc.)\n",
    "\n",
    "\n",
    "Using this data model we'll be able to build some useful analytical queries:\n",
    "- Finding relationships between the flow of immigrants and the demographic composition of the population\n",
    "- Finding seasonal changes in immigrant flows depending on time of the year and average temperatures\n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 3.2 Mapping Out Data Pipelines\n",
    "Let's summarize the steps of pipelining our source data into the target data model which were discussed earlier in sections 1 and 2.\n",
    "\n",
    "1. **Data extraction from external sources**\n",
    "    - Load all required datasets in various formats from external data sources\n",
    "    - Narrow datasets and create schema for source tables\n",
    "    - Save raw source data tables to the S3 data lake (in parquet format)\n",
    "\n",
    "2. **Data cleaning, aligning and source quality checks**\n",
    "    - Load source data tables from S3 data lake\n",
    "    - Drop rows with missing values critical for the consistency\n",
    "    - Further process source data (transform table shapes, data fields etc.)\n",
    "    - Quality checks: eliminating duplicate rows and rows with incorrect combination of field values\n",
    "    - Save preprocessed source tables to the S3 data lake (in parquet format)\n",
    "    \n",
    "3. **Forming the target data model and final quality checks**\n",
    "    - Creating fact table (fact_i94_history) and dimension tables (dim_time and dim_cities) using prepared source tables\n",
    "    - Save final fact and dimension tables to parquet files in the S3 data lake (in parquet format)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "All the logic of the data pipeline for creation of the data model is provided in the **etl.py** file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import etl\n",
    "\n",
    "input_data = {\n",
    "        \"i_94_immig\": \"../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat\",\n",
    "        \"demographic\": \"\",\n",
    "        \"airports\": \"\",\n",
    "        \"temperature\": \"../../data2/GlobalLandTemperaturesByCity.csv\",\n",
    "        \"dict_tables\": \"\"\n",
    "}\n",
    "\n",
    "output_data = \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Step 1: Data extraction from external sources** is implemented in function **load_source_data(spark, input_data, output_data)**.\n",
    "\n",
    "In this step we perform the following tasks:\n",
    "- Load all required datasets in various formats from external data sources\n",
    "- Narrow datasets and create schema for source tables\n",
    "- Save raw source data tables to the S3 data lake (in parquet format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 - Data extraction from external sources - started.\n",
      "\n",
      "Reading dictionary tables...\n",
      "289 records were successfully loaded from countries.csv\n",
      "660 records were successfully loaded from i94ports.csv\n",
      "4 records were successfully loaded from i94mode.csv\n",
      "3 records were successfully loaded from i94visa.csv\n",
      "55 records were successfully loaded from us_states.csv\n",
      "Reading i94 immigration dataset...\n",
      "3,096,313 records were successfully loaded from i94 immigration dataset.\n",
      "Reading U.S. cities demographics dataset...\n",
      "2,891 records were successfully loaded from U.S. cities demographics dataset.\n",
      "Reading airport codes dataset...\n",
      "55,075 records were successfully loaded from airport codes dataset.\n",
      "Reading global temperatures by cities dataset...\n",
      "8,599,212 records were successfully loaded from global temperatures by cities dataset.\n",
      "\n",
      "Narrowing datasets and creating correct schema for each source table...\n",
      "2,515,336 records were successfully processed into i94_source_table table.\n",
      "2,891 records were successfully processed into cities_pop_source_table table.\n",
      "21,431 records were successfully processed into airports_source_table table.\n",
      "104,085 records were successfully processed into weather_source_table table.\n",
      "\n",
      "Writing raw source tables into the data lake...\n",
      "i94_records.parquet was successfully saved in the data lake.\n",
      "demographic.parquet was successfully saved in the data lake.\n",
      "weather.parquet was successfully saved in the data lake.\n",
      "airports.parquet was successfully saved in the data lake.\n",
      "Step 1 - Data extraction from external sources - successfully completed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "etl.load_source_data(spark, input_data, output_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "For **i94 immigration** dataset we perform the following tasks:\n",
    "1. Set correct data types for the fields\n",
    "2. Translate _i94res_ and _i94cit_ codes into country names\n",
    "3. Translate _i94port_ code into city name, state names and state abbreviation name\n",
    "4. Convert _country_of_residence_, _country_of_citizenship_, _city_of_entry_, _state_of_entry_code_ and _state_of_entry_full_ into capital letters\n",
    "5. Translate _i94mode_ code into border cross method text name\n",
    "6. Translate _i94visa_ code into type of visa text name\n",
    "7. Convert dates from SAS format (with base - 1960-01-01)\n",
    "8. Add _year_, _month_ and _day_ fields for parquet partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "For **U.S. cities demographics** dataset we perform the following tasks:\n",
    "1. Set correct data types for the fields \n",
    "2. Convert _city_, _state_ and _state_code_ into capital letters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "For **airport codes** dataset we perform the following tasks:\n",
    "1. Set correct data types for the fields\n",
    "2. Extract state abbreviation from _iso_region_ field\n",
    "3. Split coordinates field into _lat_ and _lon_ fields\n",
    "4. Convert _municipality_ and _iso_region_ into capital letters\n",
    "5. Drop closed airports and those that are not in the US"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "For **global temperatures** dataset we perform the following tasks:\n",
    "1. Set correct data types for the fields\n",
    "2. Convert _country_ and _city_ into capital letters \n",
    "3. Drop cities that are not in the US\n",
    "4. Drop records before 1960\n",
    "5. Convert _longitude_ and _latitude_ from string representation (like 39.38N - 89.48W) into real numbers. For simplicity of transformation we assume that all cities in dataset will have north latitude (> 0) and west longitude (< 0) since we've dropped all cities from outside of the U.S.\n",
    "6. Add _year_, _month_ and _day_ fields for parquet partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Step 2: Data cleaning, aligning and source quality checks** is implemented in function **process_source_data(spark, input_data, output_data)**.\n",
    "\n",
    "In this step we perform the following tasks:\n",
    "- Load source data tables from S3 data lake\n",
    "- Drop rows with missing values critical for the consistency\n",
    "- Further process source data (transform table shapes, data fields etc.)\n",
    "- Quality checks: eliminating duplicate rows and rows with incorrect combination of field values\n",
    "- Save preprocessed source tables to the S3 data lake (in parquet format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2 - Data cleaning, aligning and source quality checks - started.\n",
      "\n",
      "Loading source tables from the data lake...\n",
      "2,515,336 records were successfully loaded from the data lake into i94_source_table table.\n",
      "2,891 records were successfully loaded from the data lake into cities_pop_source_table table.\n",
      "104,085 records were successfully loaded from the data lake into weather_source_table table.\n",
      "21,431 records were successfully loaded from the data lake into airports_source_table table.\n",
      "\n",
      "Cleaning and transforming source tables...\n",
      "i94_source_table was successfully preprocessed.\n",
      "180 records were dropped from the table.\n",
      "Total number of rows in preprocessed i94_source_table - 2,515,156.\n",
      "cities_pop_source_table was successfully preprocessed.\n",
      "2,295 records were dropped from the table.\n",
      "Total number of rows in preprocessed cities_pop_source_table - 596.\n",
      "airports_source_table was successfully preprocessed.\n",
      "67 records were dropped from the table.\n",
      "Total number of rows in preprocessed airports_source_table - 21,364.\n",
      "weather_source_table was successfully preprocessed.\n",
      "16,605 records were dropped from the table.\n",
      "Total number of rows in preprocessed weather_source_table - 87,480.\n",
      "\n",
      "Writing preprocessed source tables into the data lake...\n",
      "i94_records.parquet was successfully saved in the data lake.\n",
      "demographic.parquet was successfully saved in the data lake.\n",
      "weather.parquet was successfully saved in the data lake.\n",
      "airports.parquet was successfully saved in the data lake.\n",
      "Step 2 - Data cleaning, aligning and source quality checks - successfully completed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "etl.process_source_data(spark, input_data, output_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "For **i94_source_table** we perform the following tasks:\n",
    "1. Drop rows with duplicate _id_ field\n",
    "2. Drop rows with missing values in _id, state_of_entry_code, city_of_entry, arr_date_\n",
    "3. Drop rows with _dep_date < arr_date_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "For **cities_pop_source_table** we perform the following tasks:\n",
    "1. Drop rows with missing values in _city_ and _state_code_\n",
    "2. Build pivot columns for different races in given city + state\n",
    "3. Drop rows with duplicate combination of _city_ and _state_code_ fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "For **airports_source_table** we perform the following tasks:\n",
    "1. Drop rows with missing values in _iso_region_, _municipality_, _lat_ and _lon_\n",
    "2. Drop rows with duplicate rows\n",
    "\n",
    "We don't need to check for duplicate combination of _iso_region_, _municipality_ and _name_ fields as we'll build pivot table for quantity of the airports for given city + state combination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "For **weather_source_table** we perform the following tasks:\n",
    "1. Drop rows with missing values in _dt_, _avg_temperature_, _city_, _lat_ and _lon_\n",
    "2. Drop duplicate rows\n",
    "3. Join this table with **airports_source_table** using distance estimate from city coordinates (lat-lon) to airport coordinates (lat-lon) and evaluate state code for every city\n",
    "\n",
    "We drop from the resulting table all cities without state code as we cannot use them unambiguously in the future analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Step 3: Forming the target data model and final quality checks** is implemented in function **build_data_model(spark, input_data, output_data)**.\n",
    "\n",
    "In this step we perform the following tasks:\n",
    "- Load preprocessed source data tables from S3 data lake\n",
    "- Create fact table (**fact_i94_history**) and dimension tables (**dim_time** and **dim_cities**)\n",
    "- Perform quality checks on the data model\n",
    "- Save final fact and dimension tables to the S3 data lake (in parquet format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3 - Forming the target data model and final quality checks - started.\n",
      "\n",
      "Loading preprocessed source tables from the data lake...\n",
      "2,515,156 records were successfully loaded from the data lake into i94_clean_source_table table.\n",
      "596 records were successfully loaded from the data lake into cities_pop_clean_source_table table.\n",
      "87,480 records were successfully loaded from the data lake into weather_clean_source_table table.\n",
      "21,364 records were successfully loaded from the data lake into airports_clean_source_table table.\n",
      "\n",
      "Building dimension tables...\n",
      "Dimension table dim_time with 578 records was successfully created .\n",
      "Dimension table dim_cities with 596 records was successfully created .\n",
      "\n",
      "Building fact table...\n",
      "Fact table fact_i94_history with 2,515,156 records was successfully created .\n",
      "\n",
      "Step 4 - Final quality checks for the data model - started.\n",
      "\n",
      "Step 4 - Final quality checks for the data model - successfully completed.\n",
      "\n",
      "Quality checks on the data model have successfully passed.\n",
      "\n",
      "Writing preprocessed fact and dimension tables into the data lake...\n",
      "fact_i94_history.parquet was successfully saved in the data lake.\n",
      "dim_cities.parquet was successfully saved in the data lake.\n",
      "dim_time.parquet was successfully saved in the data lake.\n",
      "\n",
      "Step 3 - Forming the target data model and final quality checks - successfully completed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "etl.build_data_model(spark, input_data, output_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "For **dim_time** dimension table we perform the following tasks:\n",
    "1. Extract unique date values from _arr_date_ and _dep_date_ fields of **i94_clean_source_table** and from _dt_ field of **weather_clean_source_table** and make a union of them\n",
    "2. Add separate fields for _year_, _month_, _day_, _weekday_ and _week_ parts of date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "For **dim_cities** dimension table we perform the following tasks:\n",
    "1. Extract all attributes from **cities_pop_clean_source_table**\n",
    "2. Transform **airports_clean_source_table** into pivot table with number of airports per city + state combination\n",
    "3. Add _number_of_airports_ field in resulting **dim_cities** table by joining _municipality_ & _iso_region_ composite key with _city_ & _state_code_ omposite key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "For **fact_i94_history** dimension table we perform the following tasks:\n",
    "1. Extract following attributes from **i94_clean_source_table**: _id, country_of_residence, country_of_citizenship, city_of_entry, state_of_entry_code, border_cross_method, type_of_visa, class_of_admission, gender, age, arr_date, dep_date_\n",
    "2. Add fields for _year_, _month_ and _day_ parts of the _arrival_date_\n",
    "3. Add _avg_temperature_ field in resulting **fact_i94_history table** by joining _city_of_entry_ & _state_of_entry_code_ & _YEAR(arr_date)_ & _MONTH(arr_date)_ composite key with _city_ & _state_ & _YEAR(dt)_ & _MONTH(dt)_ omposite key (Test datasets for i94 and temperature don't contain overlaping periods of time, so _avg_temperature_ field will be null)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "After forming target tables we perform final quality checks (see below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "We perform data quality checks through all three steps of data transformation into the target data model.\n",
    "\n",
    "During **Step 3** we performed the following final checks in function **check_model_quality(spark, model_data)** to ensure quality of our fact and dimension tables:\n",
    "- Check if **fact** and **dimension** tables contain greater than zero records\n",
    "- Check if **fact** table doesn't contains dates missing in **dim_time** table\n",
    "\n",
    "We ran this function in Step 3 above.\n",
    "\n",
    "Integrity constraints on the relational database (e.g., unique key, data type, etc.) were implemented in the previous steps of pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Data dictionary for the target data model is provided in the file **dictionary.pdf**.\n",
    "\n",
    "Schemas for all tables used in our pipeline is provided in the file **dictionary_Schema.txt**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people.\n",
    "\n",
    "In this project we are dealing with a huge amount of data. As we see from one month's immigration data sample dataset for April 2016 there is over 3 million rows of events for only 30 days. This is apparently a Big Data scenario.\n",
    "Therefore, we must use tools with scalability in mind. So we decided to use scalable processing capabilities of Apache Spark and scalable storage capabilities of AWS S3.\n",
    "\n",
    "For this project, we use a star schema optimized for queries on immigration analysis.\n",
    "According to the selected schema we'll build one fact table which contains measures for the immigration data and several dimension tables which contain attributes describing our target entities.\n",
    "\n",
    "Using this data model we'll be able to build some useful analytical queries:\n",
    "- Finding relationships between the flow of immigrants and the demographic composition of the population\n",
    "- Finding seasonal changes in immigrant flows depending on time of the year and average temperatures\n",
    "- etc.\n",
    "\n",
    "Monthly updating of our datd would be adequate for the needs of the analytics teams.\n",
    "Anyway we can increase the frequency of update up to a week or day, for example, without having to make architectural changes in the pipeline.\n",
    "\n",
    "In the scenario when data volumes will rapidly grow (100x, for example) we should consider two options:\n",
    "- to scale underlying Spark cluster hardware.\n",
    "- to implement Steps 1 and 2 of our pipeline in Apache Airflow using data partitioning. We could use logical partitioning to parallelize data processing where different soruce tables will be processed separately from each other. Also we could use data partiotioning where each run of our DAG will process only smaller data segment based on year/month partitioning of our source data.\n",
    "\n",
    "If we need to update target fact and dimension tables on a regular schedule (e.g., on a daily basis by 7am every day) we can implement Step 3 of our pipeline as an independent DAG in Airflow and schedule this DAG to run on a daily basis. \n",
    "\n",
    "Since we're using AWS S3 as main storage option for our data lake we can either organize access to the data by queries in-place or transfer them to multiuser databases such as redshift, etc. \n",
    "Therefore, if the database needs to be accessed by 100+ people that shouldnt be an issue.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
